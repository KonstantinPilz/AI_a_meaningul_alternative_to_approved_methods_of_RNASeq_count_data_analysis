---
title: "MLSeq_MAIT"
output:
  html_notebook:
    toc: yes
    theme: united
---
This is the analysis of the cervical data set provided by the authors of MLSeq.



1. setup
```{r}
library(knitr)
opts_chunk$set(tidy = FALSE,
               dev = "pdf",
               fig.show = "hide",
               message = FALSE,
               fig.align = "center",
               cache = FALSE)

```
libraries
```{r}
library("MLSeq")
library("DESeq2")
library("edgeR")
library("VennDiagram")
library("pamr")
library("caret")
library("hexbin")
library("pheatmap")
library("RColorBrewer")
library("ggplot2")
library("tidyverse")
library("BiocParallel")

```
Making it possible to run both on local machine as well as on cluster
```{r}
local <- FALSE
recompute <- 0
#cores
if (!local){
  mcparam <- MulticoreParam(4)
  register(mcparam)
}

prefix <- ifelse(local, "~", "")
dir <- file.path(prefix, "data/bioinf/projects/data/2022_MLseq_KP/MAIT_MLSeq")
data_dir <- file.path(dir, "data/")
result_dir <- file.path(dir, "results/")
graphics_dir <- file.path(dir, "graphics/")
```
2. load data

Data input
```{r}
load("/data/bioinf/projects/data/2022_MLseq_KP/MAIT_DESeq2/results/05_dds_pre_processed.Rdata")
#head(dds_K12)
count<- dds_K12
head(data)

count <- assay(dds_K12) # I recreated to count table from the dds for the following steps in the MLSeq workflow
#look at object
count <- count[,c(1,3,5,7,9,2,4,6,8,10)]

class <- data.frame(condition = factor(rep(c("T","C"), c(5, 5))))
colnames(count) <- 1:10
```
3. pre-filtering
The seed determines how the samples are randomized -> For reproducibility use same seed
In particular it determines the variable ind
We do not perform a differential expression analysis to select differentially expressed genes. However, in practice, DE analysis might be performed before fitting classifiers. Here, we selected top 100 features having the highest gene-wise variances in order to decrease computational cost.
```{r}
set.seed(2120)

vars <- sort(apply(count, 1, var, na.rm = TRUE), decreasing = TRUE)

data <- count[names(vars)[13000:14000], ]
#head(data[ ,1:10])
```
Input from DESeq preprocessing
4. Split data into testing and training set
Since we want to build a classification model, we need training data.
After training, we need more data to assess the performance

Since the number of samples is only 5 each, the accuracy will be 100% regardless of how the data is split between training and testing. To increase the value of the results from sparse classifiers, I will take as many samples for the training as possible.
```{r}
nTest <- ceiling(ncol(data) * 0.2)
ind <- sample(ncol(data), nTest, FALSE)

# Minimum count is set to 1 in order to prevent 0 division problem within
# classification models.
data.train <- as.matrix(data[ ,-ind] + 1) #offset to make sure there is no malfunctioning
#K# training data: all data except for ind -> 70% -> 40 samples
data.test <- as.matrix(data[ ,ind] + 1)#K# all lines (genes) of the matrix, but only the columns specified in ind
#K# test data: the remaining data -> ind -> 30% -> 18 samples

#?# Why this class type?
#K# I think it contains the classification of each sample
classtr <- DataFrame(condition = class[-ind, ])
classts <- DataFrame(condition = class[ind, ])

#DESeqDataSets, input for MLSeq
data.trainS4 = DESeqDataSetFromMatrix(countData = data.train,
                                      colData = classtr,
                                      design = ~1)
data.testS4 = DESeqDataSetFromMatrix(countData = data.test,
                                     colData = classts,
                                     design = ~1)

```
5. Training classifiers
First, the data is normalized using one of four methods
deseq-rlog: Normalization with deseq median ratio method.

Train all the sparse classifiers

```{r}
recompute <- 1
# Define control lists.
ctrl.continuous <- trainControl(method = "repeatedcv", number = 5, repeats = 10)
ctrl.discrete <- discreteControl(method = "repeatedcv", number = 5, repeats = 10,
                             tuneLength = 10)
ctrl.voom <- voomControl(method = "repeatedcv", number = 3, repeats = 10,
                             tuneLength = 10)

file_NSC <- file.path(data_dir, "02_NSC.Rdata")
file_plda <- file.path(data_dir, "03_plda.Rdata")
file_plda2<- file.path(data_dir, "04_plda2.Rdata")
file_voomNSC <- file.path(data_dir, "05_voomNSC.Rdata")
```
```{r}
recompute <- 1

if (recompute){
  #voom-based
  fit.voomNSC <- classify(data = data.trainS4, method = "voomNSC",
                         normalize = "deseq", ref = "C", control = ctrl.voom, na.rm = TRUE)

  save(fit.voomNSC, file= file_voomNSC)

} else {

  load(file_voomNSC)
}
print("done")
genes.vnsc <- selectedGenes(fit.voomNSC)
```
```{r}
if (recompute){
  #continuous
  fit.NSC <- classify(data = data.trainS4, method = "pam",
                 preProcessing = "deseq-vst", ref = "C", tuneLength = 10,
                 control = ctrl.continuous)
  save(fit.NSC, file = file_NSC)
} else {
    load(file_NSC)
}
print("done")
pam.final <- trained(fit.NSC)$finalModel   ## 'pamrtrained' object.
geneIdx <- pamr:::pamr.predict(pam.final, pam.final$xData, threshold = pam.final$threshold, type = "nonzero")

genes.pam <- colnames(pam.final$xData)[geneIdx]
```
```{r}
if (recompute){

  #discrete
  fit.plda <- classify(data = data.trainS4, method = "PLDA", normalize = "deseq",
                     ref = "C", control = ctrl.discrete)
  save(fit.plda, file = file_plda)
} else {
    load(file_plda)
}
print("done")
genes.plda <- selectedGenes(fit.plda)
```
```{r}
if (recompute){

  #discrete


  fit.plda2 <- classify(data = data.trainS4, method = "PLDA2", normalize = "deseq",
                     ref = "C", control = ctrl.discrete)
  save(fit.plda2, file =file_plda2)
} else {

  load(file_plda2)
}
print("done")
genes.plda2 <- selectedGenes(fit.plda2)
```


```{r}
tmp.list <- list(genes.pam, genes.plda, genes.plda2, genes.vnsc)


nn <- c(length(genes.pam), length(genes.plda), length(genes.plda2), length(genes.vnsc))
ooo <- order(nn, decreasing = TRUE)

tmp.list <- tmp.list[ooo]
#K# saving the list of genes
capture.output(tmp.list, file = file.path(result_dir, "02_summary_sparse_classifiers.txt"))
capture.output(genes.pam, file= file.path(result_dir, "03_pam_genes.txt"))
capture.output(genes.plda, file= file.path(result_dir, "04_plda_genes.txt"))
capture.output(genes.plda2, file= file.path(result_dir, "05_plda2_genes.txt"))
capture.output(genes.vnsc, file= file.path(result_dir, "06_vnsc_genes.txt"))

```
Have a look at accuracies

```{r}
show(fit.NSC)
show(fit.plda)
show(fit.plda2)
show(fit.voomNSC)
```
venn diagram of selected features by sparse classifiers
```{r}
common <- tmp.list[[1]]
for (i in 2:(length(tmp.list))){
  tmp2 <- tmp.list[[i]]
  tmp <- common[common %in% tmp2]
  common <- tmp
}

## ----venn_diagram, echo = FALSE-----------------------------------------------
venn.plot <- venn.diagram(
  x = list(voomNSC = genes.vnsc, NSC = genes.pam, PLDA = genes.plda, PLDA2 = genes.plda2),
  height = 1200, width = 1200,
  resolution = 200,
  filename = file.path(graphics_dir, "01_Selected_features.png"), imagetype = "png",
  col = "black",
  fill = c("khaki1", "skyblue", "tomato3", "darkolivegreen3"),
  alpha = 0.50,
  cat.cex = 1.2,
  cex = 1.5,
  cat.fontface = "bold"
)
```